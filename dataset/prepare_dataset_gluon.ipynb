{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "dataset_root = '/home/aiteam/tykim/video_recog/dataset'\n",
    "\n",
    "mix_dataset_root = os.path.join(dataset_root, 'mix_dataset')\n",
    "mix_dataset_root_path = Path(mix_dataset_root)\n",
    "mix_dataset_root_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "mix_dataset_train_path = mix_dataset_root_path.joinpath('train')\n",
    "mix_dataset_train_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "mix_dataset_val_path = mix_dataset_root_path.joinpath('val')\n",
    "mix_dataset_val_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mix_dataset_anno_path = mix_dataset_root_path.joinpath('anno')\n",
    "mix_dataset_anno_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_datasets = {'AIRTLab':('non-violent', 'violent', 0.5), 'RLV':('NonViolence','Violence', 0.9), 'surv_fight':('noFight','fight', 0.8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "AIRTLab ('non-violent', 'violent', 0.5)\n",
      "train_nv :  60 train_v: 115 val_nv :  60 val_v :  115\n",
      "=========================================\n",
      "RLV ('NonViolence', 'Violence', 0.9)\n",
      "train_nv :  900 train_v: 900 val_nv :  100 val_v :  100\n",
      "=========================================\n",
      "surv_fight ('noFight', 'fight', 0.8)\n",
      "train_nv :  120 train_v: 120 val_nv :  30 val_v :  30\n"
     ]
    }
   ],
   "source": [
    "train_cnt = 1\n",
    "val_cnt = 1\n",
    "train_prefix = 'train'\n",
    "val_prefix = 'val'\n",
    "\n",
    "train_anno_path = mix_dataset_anno_path.joinpath('train.txt')\n",
    "train_anno = open(train_anno_path, \"w\")\n",
    "\n",
    "val_anno_path = mix_dataset_anno_path.joinpath('val.txt')\n",
    "val_anno = open(val_anno_path, \"w\")\n",
    "\n",
    "\n",
    "for dataset_name, info in other_datasets.items():\n",
    "    print('=========================================')\n",
    "    print(dataset_name, info)\n",
    "    dataset_path = Path(dataset_root).joinpath(dataset_name)\n",
    "\n",
    "    nv_path = dataset_path.joinpath(info[0])\n",
    "    v_path = dataset_path.joinpath(info[1])\n",
    "\n",
    "    nv_vid_list = list(nv_path.rglob('*.[ma][pv][4i]'))\n",
    "    v_vid_list = list(v_path.rglob('*.[ma][pv][4i]'))\n",
    "    # print(len(nv_vid_list))\n",
    "    # print(len(v_vid_list))\n",
    "\n",
    "    num_train_nv = int(len(nv_vid_list) * info[2])\n",
    "    num_train_v = int(len(v_vid_list) * info[2])\n",
    "    \n",
    "    \n",
    "    train_nv_list = random.sample(nv_vid_list, num_train_nv)\n",
    "    val_nv_list = list(filter(lambda x: x not in train_nv_list, nv_vid_list))\n",
    "\n",
    "    \n",
    "    train_v_list = random.sample(v_vid_list, num_train_v)\n",
    "    val_v_list = list(filter(lambda x: x not in train_v_list, v_vid_list))\n",
    "\n",
    "    print('train_nv : ', len(train_nv_list), 'train_v:', len(train_v_list), 'val_nv : ', len(val_nv_list), 'val_v : ', len(val_v_list))\n",
    "    ############ TRAIN ###############\n",
    "    for train_nv in train_nv_list:\n",
    "        dst_name = f'{train_prefix}_{train_cnt}.mp4'\n",
    "        # 파일 이동\n",
    "        os.rename(train_nv, mix_dataset_train_path.joinpath(dst_name))\n",
    "        # annotation 작성\n",
    "        train_anno.write(str(dst_name) + \" \" + str(int(200)) + \" \" + str(int(0)) + \"\\n\")\n",
    "        train_cnt += 1\n",
    "\n",
    "\n",
    "    for train_v in train_v_list:\n",
    "        dst_name = f'{train_prefix}_{train_cnt}.mp4'\n",
    "        # 파일 이동\n",
    "        os.rename(train_v, mix_dataset_train_path.joinpath(dst_name))\n",
    "        # annotation 작성\n",
    "        train_anno.write(str(dst_name) + \" \" + str(int(200)) + \" \" + str(int(1)) + \"\\n\")\n",
    "        train_cnt += 1\n",
    "\n",
    "    \n",
    "    # ############ VALIDATION ###############\n",
    "    for val_nv in val_nv_list:\n",
    "        dst_name = f'{val_prefix}_{val_cnt}.mp4'\n",
    "        os.rename(val_nv, mix_dataset_val_path.joinpath(dst_name))\n",
    "        # annotation 작성\n",
    "        val_anno.write(str(dst_name) + \" \" + str(int(200)) + \" \" + str(int(0)) + \"\\n\")\n",
    "        val_cnt += 1\n",
    "\n",
    "    for val_v in val_v_list:\n",
    "        dst_name = f'{val_prefix}_{val_cnt}.mp4'\n",
    "        os.rename(val_v, mix_dataset_val_path.joinpath(dst_name))\n",
    "        # annotation 작성\n",
    "        val_anno.write(str(dst_name) + \" \" + str(int(200)) + \" \" + str(int(1)) + \"\\n\")\n",
    "        val_cnt += 1\n",
    "    \n",
    "val_anno.close()\n",
    "train_anno.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "\n",
    "len(list(Path('/home/aiteam/tykim/video_recog/dataset/mix_dataset/val').rglob('*.mp4')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "test = [1,23,4,5,6]\n",
    "test2 = [9,7,77,888,88]\n",
    "random.sample(test, 2). + random.sample(test2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "l_dup = [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3]\n",
    "\n",
    "print(random.sample(test, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nv_10'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('/home/aiteam/tykim/video_recog/dataset/mix_dataset/non-violent/nv_10.mp4').stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_img_paths = np.split(img_paths, [partition * (idx + 1) for idx in range(num_process-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [1,2,6,8]; l2 = set([2,3,5,8])\n",
    "\n",
    "list(filter(lambda x: x not in l2, l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
