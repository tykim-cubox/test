{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = '/workspace/dataset'\n",
    "\n",
    "mix_dataset_root = os.path.join(dataset_root, 'mix_dataset_action2')\n",
    "mix_dataset_root_path = Path(mix_dataset_root)\n",
    "mix_dataset_root_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "mix_dataset_vid_path = mix_dataset_root_path.joinpath('videos')\n",
    "mix_dataset_vid_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "training_path = mix_dataset_vid_path.joinpath('training')\n",
    "training_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "validation_path = mix_dataset_vid_path.joinpath('validation')\n",
    "validation_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_v_path = training_path.joinpath('violent')\n",
    "train_v_path.mkdir(parents=True, exist_ok=True)\n",
    "train_nv_path = training_path.joinpath('non-violent')\n",
    "train_nv_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "val_v_path = validation_path.joinpath('violent')\n",
    "val_v_path.mkdir(parents=True, exist_ok=True)\n",
    "val_nv_path = training_path.joinpath('non-violent')\n",
    "val_nv_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_datasets = {'AIRTLab':('non-violent', 'violent', 0.3), 'RLV':('NonViolence','Violence', 0.9), 'surv_fight':('noFight','fight',0.8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_dataset_nv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_dataset_nv_path.joinpath(f'nv_{0}.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 진짜 옮기는거 말고 annotation txt만드는 것 부터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv_cnt = 1\n",
    "v_cnt = 1\n",
    "v_prefix = 'v'\n",
    "nv_prefix = 'nv'\n",
    "\n",
    "train_anno_path = mix_dataset_root_path.joinpath('train_anno.txt')\n",
    "train_anno = open(train_anno_path, \"w\")\n",
    "\n",
    "val_anno_path = mix_dataset_root_path.joinpath('val_anno.txt')\n",
    "val_anno = open(val_anno_path, \"w\")\n",
    "\n",
    "\n",
    "\n",
    "for dataset_name, info in src_datasets.items():\n",
    "    print('=========================================')\n",
    "    print(dataset_name, info)\n",
    "    dataset_path = Path(dataset_root).joinpath(dataset_name)\n",
    "\n",
    "    nv_path = dataset_path.joinpath(sub_dir_name[0])\n",
    "    v_path = dataset_path.joinpath(sub_dir_name[1])\n",
    "\n",
    "    nv_vid_list = list(nv_path.rglob('*.[ma][pv][4i]'))\n",
    "    v_vid_list = list(v_path.rglob('*.[ma][pv][4i]'))\n",
    "    print(len(nv_vid_list))\n",
    "    print(len(v_vid_list))\n",
    "\n",
    "    num_train_nv = int(len(nv_vid_list) * info[2])\n",
    "    num_train_v = int(len(v_vid_list) * info[2])\n",
    "    \n",
    "    train_nv_list = random.sample(nv_vid_list, num_train_nv)\n",
    "    val_nv_list = list(filter(lambda x: x not in train_nv_list, nv_vid_list))\n",
    "\n",
    "    print('train_nv:', len(train_nv_list), 'train_v:', len(train_v_list), 'val_nv:', len(val_nv_list), 'val_v:', len(val_v_list))\n",
    "\n",
    "    for train_nv in train_nv_list:\n",
    "        \n",
    "\n",
    "    \n",
    "    for nv_vid in nv_vid_list:\n",
    "        os.rename(nv_vid, mix_dataset_nv_path.joinpath(f'nv_{nv_cnt}.mp4'))\n",
    "        nv_cnt += 1\n",
    "    for v_vid in v_vid_list:\n",
    "        os.rename(v_vid, mix_dataset_v_path.joinpath(f'v_{v_cnt}.mp4'))\n",
    "        v_cnt += 1\n",
    "\n",
    "\n",
    "# AIRTLab ('non-violent', 'violent')\n",
    "# 120\n",
    "# 230\n",
    "# RLV ('NonViolence', 'Violence')\n",
    "# 1000\n",
    "# 1000\n",
    "# surv_fight ('noFight', 'fight')\n",
    "# 150\n",
    "# 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "len(list(Path('/home/aiteam/tykim/video_recog/dataset/mix_dataset/violent').rglob('*.mp4'))), len(list(Path('/home/aiteam/tykim/video_recog/dataset/mix_dataset/non-violent').rglob('*.mp4')))\n",
    "# (1380, 1270)\n",
    "\n",
    "# Split train-val dataset\n",
    "np.random.permutation(10)\n",
    "\n",
    "# 나중에 split을 하는게 아니라 처음부터 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gluon 형식으로 활용가능할지?\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = list(Path('/workdspace/dataset/mix_dataset/train').rglob('*.[ma][pv][4i]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
